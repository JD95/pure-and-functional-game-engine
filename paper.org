# org-mode settings
#+STARTUP: indent
#+STARTUP: hidestar

# paper meta 
#+TITLE: A Pure and Parallel Game Engine
#+AUTHOR: Jeffrey Dwyer
#+DATE: 11/15/2017
#+OPTIONS: toc:nil

# latex options
#+LATEX_HEADER: \usepackage[margin=1.0in]{geometry}
#+LATEX_HEADER: \usepackage{apacite}
#+LATEX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{setspace}
#+LATEX_HEADER: \usepackage{appendix}
#+LATEX_HEADER: \usepackage{titlesec}
#+LATEX_HEADER: \linespread{2.0}
#+LATEX_CLASS_OPTIONS: [12pt]

\titleformat*{\section}{\large\bfseries}
\titleformat*{\subsection}{\small\bfseries}

\begin{abstract}

It is the growing trend in software development to integrate multicore processing to achieve performance as the speed of single processes improves at slower rates. Despite this, game engine architectures have changed little in respect to parallelization. This paper proposes how functional programming can be used to build game engines which take advantage of multiple processors without the complexities that existing engines would face. Concerns with the programming style forced by functional languages will be addressed by adapting techniques used in other reactive applications. Finally, several techniques for minimizing or eliminating the runtime costs of functional programming will be discussed to show that a functional engines have the potential to match or exceed the performance of existing single processor engines. 

\end{abstract}

* Introduction

Game engines stand in a cross roads between many fields, benefiting from research in topics from physical simulations to artificial intelligence (AI). Popular engines like Unity support AI, physics, animation, scripting, input, multimedia, and networking cite:messaoudi_dissecting_2015. 

The high performance demanded of games forces their engines to be optimized so that all of the intensive calculations for a single frame of the game can fit within a mere sixteen millisecond window. This is the speed needed for a frame rate of sixty frames per second, the rate at which the human eye cannot notice the frame changes. While this goal was not achievable until the last decade, each time the processing power of computers increased, engines were able to do more as a result.  The famous Moore's Law predicted a doubling of computing power every two years so this tactic was reasonable cite:present_cramming_2000. This pace was continuous until around 2015 when companies like Intel announced that their pace had slowed to almost two and a half years with a predicted geometric slowing every year. With processors reaching the physical limits of their individual capabilities, there has been a movement toward mutlicore design in software to compensate cite:theis_end_2017.

Unfortunately, years of optimization for a single core processor leaves many of the most popular game engines unable to adapt to multicore designs without a massive reworking cite:anderson_case_2008. This is unfortunate because many aspects of modern engine architectures lend themselves toward parallel execution. If the industry can no longer rely on the improvements of single processors to continue pushing the boundaries of what is possible in video games, then engines must be redesigned to take advantage of new multi-core processors. 

This paper will proceed in four sections. The first section on game engine architecture will outline the components of modern game engines. The second section will identify opportunities for parallel execution and introduce functional programming as a means to implement parallelism. The third section will cover how traditional ideas about graphical applications can be adapted to be feasible in a functional language. The final section will address the performance concerns from using a functional programming techniques in high performance applications.

* Game Engine Architecture

All graphical programs follow a similar execution flow. First, input is collected from user interfaces. Input information is then fed into internal system logic which calculates the a new  application state cite:czaplicki_asynchronous_2013. Finally an  image is displayed to the screen based on the sate and the process repeats. Game engines follow a similar pattern, except the internal logic is typically divided more explicitly. 

Tagliasacchi et. al describes engine updates as a data flow from user input to the resulting image or frame. Input is then given to the entities within the game, which decide how to change the virtual world. Once the changes have been calculated they are given to a physics simulation which then implements movements or forces exerted within the world. Any collisions, with the ground for example, are taken into account and the entities react. Finally, the positions and orientations of models within the world are rendered which will create a frame to be displayed on screen cite:tagliasacchi_cascade:_2008.

Modern games often have thousands of complex entities, adding more pressure on to complete as soon as possible. Typical tactics to achieve speed involve special algorithms to minimize work and allocations made in system memory. These techniques apply to multicore designs as well as single processor architectures. There are however, certain advantages that a multicore system would have over standard implementations today.

If two operations do not depend on eachother to complete, then being able to finish those tasks at the same time would yield a theoretical doubling of performance. While a perfect double in performance is rarely possible, due to the overhead of distributing tasks, in the tight requirements of game engines even a fifty percent increase could be the difference between poor and professional grade performance. Modern chipsets typically have at least four cores, leaving potential for tripling of performance if only the engine can take advantage of them.
 
* Achieving a Parallel Design 

For two tasks to be run at the same time, their results must be independent of each other. While data in a game engine flows through the system in a linear fashion, there are calculations which can be completed in parallel. For example, each unit of AI within the system could decide its next action based solely on the world configuration in the previous frame. Each unit would need only the previous state to then be run at any time and in any order in relation to the other units. Most engine systems have this property with only two portions being completely serial, the construction of the render tree and interaction resolution cite:tulip_multi-threaded_2006.

The render tree is a data structure which the rendering module uses to determine the order to draw elements. With certain visual effects, like transparency, the order of rendering matters as transparent objects must be rendered after other objects to achieve the desired result. Other effects might be rendered over multiple passes or require the pixels from the previous pass, like motion blurs. This process depends heavily on a serial ordering and this is impossible to parallelize, even fully featured engines today spend most of their time in rendering cite:messaoudi_dissecting_2015.

The other completely serial process is interaction resolution, which consists of resolving interactions between entities. This mostly occurs after physics simulations. The discrete nature of physics simulations allows for objects to temporarily intersect and need correction before the update can continue. Similar to the rendering order, results of future resolutions depend on previous ones, so this process cannot be parallelized. Beyond these two systems most of the remaining processes can incorporate some level of parallel execution. 

** Applying Parallelism

Tulip et. al outline several considerations to be taken when parallelizing the engine. First, the number of parallel tasks (threads) should be minimized to the number of cores available. Second, the creation and destruction of threads should be avoided while processing data. Third, the synchronization between threads should be minimized. Finally, the workload should be balanced across threads cite:tulip_multi-threaded_2006.

Several features which can be parallelized are: interpolation of animations, the application of lighting and textures, sound source contributions, and rendering frames between updates cite:tulip_multi-threaded_2006. In his white paper, Andrews suggests dividing the work between different managers and using them to generate and distribute tasks to various worker treads. These tasks are created via messages between the different managers. When the next frame is to be calculated each manager would determine what work that subsystem needs to do. In this model, the managers serve as the main division of work between the different CPU cores. Balance across the various cores is achieved by only dividing the managers if there are enough cores to do so cite:andrews_designing_2009.

Although this design presents a simple method of converting existing architectures into parallel ones, there remain several challenges to overcome. One of the main concerns in concurrent programming is the possibility of dead locks, a situation in which many separate processes are waiting on each other in a cycle for some resource. While work is separated between managers, there is no guarantee that each subsystem will not affect the data needed by other systems. 

In most programming languages, there is no restriction on what processes can modify, in fact engines often take advantage of this to increase efficiency in some cases cite:tagliasacchi_cascade:_2008. When translating these modules into a parallel system, any data which would be used by different processes would have to be put under a lock, allowing only one thread to work with the data at any given time. If a thread needs to modify data which is currently locked, it can only wait until the lock is lifted. If the waiting queue for locks ever becomes cyclical, then the system stops because no work can be done, a dead lock. 

One technique to avoid dead locks is software transactional memory (STM). This methodology performs small, reversible tasks which either complete successfully or are rolled back. Atomicity, a name given to the previous features, is what allows for normal locking to be avoided all together using STM. Lock free data structures using STM are faster than their locking counterparts, however programming using STM is complex in languages that do not directly support it cite:discolo_lock_2006. These challenges are not unique to game engines and their solution may come from a more general approach to simplifying parallel design.

** Functional Programming

In his Turing award lecture, John Backus posed the question of whether programming languages could grow out of their trend of becoming larger, but not more expressive. He noted that the many changeable parts of existing languages have little to no expressive power, thus leading to many features being built into the language itself. These properties make such languages difficult to reason about. He concluded by proposing functional programming as an alternative cite:backus_can_1978. 

Functional programming is a model of computation based on the Lambda Calculus of Alonzo Church and naturally lends itself to parallel computing given the semantic differences from normal programming styles cite:backus_can_1978. Instead of building a system using a series of steps, programs can be thought of as a series of almost algebraic expressions. So long as certain rules are followed, it does not matter in what order the sub-expressions are evaluated. In fact, by default the order of evaluation taken out of the hands of the programmer cite:jones_implementing_1993. This is desirable for parallel execution in that almost any sub-expression can be calculated independently. 

For example, the classic quicksort algorithm sorts a list by dividing the list in to paritions and sorting those. Once the lsit has been divided, the two paritions can be sorted in parallel.

\vspace{10mm}
\begin{spacing}{0.5}
\begin{lstlisting}[language=Haskell, xleftmargin=.2\textwidth] 
qsort :: Ord a => [a] -> [a]
qsort [] = []
qsort (x:xs) = qsort ys ++ x : qsort zs
  where
    (ys, zs) = partition (< x) xs 

\end{lstlisting}
\end{spacing}
\vspace{10mm}

The above is an implementation of quicksort in Haskell. A given list is split into partitions (ys and zs) and then those paritions are also quicksorted. By default, the sorting will happen in sequence, with one half completing before the other half is worked on. However, given the nature of functional languages, we do not have to think of the process as a series of steps, but rather as a graph of expressions to evaluate.

#+CAPTION: The Quicksort function as a graph
[[./function-graph-example.png]]

Because there are no dependencies on state between any of the leaves in such graphs, each can be evaluated and reduced in any order or at the same time. It is this property which makes languages like Haskell so easy to run in parallel. Most programs need only a small annotation to indicate that the expression should be evaluated at the same time.

That being said, because these values are immutable, the original list is not being sorted, rather a new, in order list is being created. This is problematic as it takes more time to create new data than it does to update existing data. Another issue is that functional languages, Haskell included, manage their memory using automatic processes called garbage collection. Every so often, the program will be paused so memory which is no longer needed can be freed. Again, these types of delays prevent the kind of performance needed by modern video games. 

For this solution to the parallelization problem to be useful, two issues must be considered. First, can functional languages describe complex graphical systems like game engines with at least the same amount of effort as normal languages? Second, can a functional engine be as performant as engines written in traditional languages like C and C++?

The second challenge will be addressed using several optimization techniques to minimize and eliminate the creation of new data, increase spatial locality, and minimize or eliminate garbage collection. While the execution of functional languages is different at high level, the goals of optimization remain the same. 

The first challenge will be addressed using research into graphical interfaces designed in the functional style. In many ways game engines behave identically to normal graphics applications like excel or internet browsers cite:tulip_multi-threaded_2006. Any techniques used to create these kinds of graphical application can also be used in game engine design.

* Representing the game loop using functional reactive programming 

Graphical application frameworks today take user input and allow for individual components of the application handle. An example would be a button which, when clicked, modifies the state of a pop up to be visible. In a functional paradigm, where arbitrary modifications of data are not allowed, the relations between different entities must be made explicit. 

As such, there is a movement toward a model which represents the application like a circuit. User inputs and events enter the circuit which causes changes to the displayed image. This technique is not specific to functional programming, and so the functional variation of this model is called "Functional Reactive Programming" or FRP. In his seminal paper on FRP, Elliot defined a system based on two primitive types, Behaviors, Events, and a set of combinators for generating new values based on those primitives cite:elliott_push-pull_2009. 

Elliot describes behaviors as functions from time to a value. An example of this would be a ball in the air whose height is dependent on time and the velocity of the ball. As time progresses, the height of the ball decreases. These behaviors can be used to create more behaviors dependent on other streams of values. Character animations fall under the category of a behavior. Each of the joints depends on a stream of angles and positions to progress the animation over time. 

-- Possibly insert a picture of a cahracter joint graph here?

An Event is a function from time to a possible value. The classic example of an event would be a mouse click. If one where to plot the function of an event it would remain mostly at zero until the event occurred, which would be visible as a small spike in the value before it returns to nothing. Events can be used to model discrete occurrences within the system which are then used by behaviors to alter the interface cite:wan_functional_2000.

#+CAPTION: A reactive network for unit position
[[./frp-unit-example.png]]

In the above example, we can see two behaviors, the player unit's position and the alarm's position. Over time, the player's position will change which causes the active state of the alarm to be recalculated. Here, the difference between the player's position and the alarm is calculated and then that result is checked to see if it is less than five. The alarm triggering can be considered an event since it only occurs at discrete points in time. 

The simplicity of reactive systems defined like this have found success even outside of a functional context. Audio systems like Max represent sysnthesizers as networks of audio signals, allowing the user to design graphically. Even the Unreal game engine provides a model of entity behavior in a reactive style. Although functional languages cannot model an engine in the conventional way, an FRP alternative is a natural and proven solution.

#+CAPTION: Blueprints in the Unreal Engine
[[./unreal-blueprints.jpg]]
 
** Alternative and Improved formulations of FRP

Although FRP creates a rich and expressive style to model a game engine with, there are several performance issues with the semantics as originally defined. 

For instance, given that all values are dependent on time, all values within the system must be constantly recalculated, which causes large amounts of wasteful work calculating values which have not changed. In Czaplicki and Chong's formulation of FRP, changes do not propagate unless a discrete event occurs. This is much more suited for graphical interfaces due to that face that the user can only interact with the system in discrete ways cite:czaplicki_asynchronous_2013. 

Another problem is that the original semantics also force all previous values for behaviors and events to be stored for the duration of the program. As time progresses, the memory usage slowly builds. In his reformulation, Elliott introduced the idea of reactive values and push-pull semantics to address the same performance issues. These reactive values allow for the same mental model for behaviors to be used without the performance loss cite:elliott_push-pull_2009.

An alternative to reactive values was presented in Nilsson et. al with the continuation formulation of FRP. In is model, direct manipulation of behaviors was removed in favor of a set of functions on already defined behaviors. This allowes for a faster implementation cite:nilsson_functional_2002.

Many of these techniques have been implemented and used in game development with Haskell already. Libraries like Reflex have been used to create inerative web applications. Another FRP library, Yampa has been used in the development of several games for android. 

-- Citations to these libraries and the links to the games

* Addressing Efficency Concerns 

Although pure functional programming allows for expressivity and simple parallelization, there are performance costs which must be addressed. 

The price for purity is a new allocation for every change or update to existing data. Operations on existing data are cheap time-wise, but creating new data is expensive. Many optimizations done by modern engines focus on reusing existing data to prevent new allocations whenever possible. Luckily, pure functional languages allow for the compiler to perform many complex optimizations not possible in other languages. Once technique for reducing allocations is to eliminating intermediate data from being created between data producers and data consumers, also known as fusion. 

** Fusion

Fusion eliminates intermediate data structures like a lists due to the properties of the functions. In the functional style, functions like map, fold, and filter are common tools used to manipulate data structures. Due to referential transparency, functions can be manipulated almost like algebraic expression in math where redundancies can be removed. 

\begin{spacing}{0.5}
\begin{lstlisting}[language=Haskell, xleftmargin=.3\textwidth]

map (g . f) = map g . map f

\end{lstlisting}
\end{spacing}
\vspace{5mm}

In the case of the function map, which applies a function to all values of a list, the composition of two maps is equal to mapping the composition of both functions. So rather than create a new list for the result of map f and then a new structure for map g, the optimized version simply applies (g . f) to every element of the input list and creates only a single new list. List are not the only structures which can benefit from fusion. 

Meijer et. al formalized several recursion schemes which could replace normal recursion as the basic building block of functional programs. These recursion schemes were divided into two categories, anamorphisms, which produce new values and catamorphisms, which consume values. In general, it is the pairing of an anamorpic producer and a catamorphic consumer that allows for fusion to occur cite:meijer_functional_1991. Fusion can occur for any recursive data structures, not just lists cite:bernardy_composable_2016.

Certain modules within the engine serve only to produce or consume data. Several producers are user input and networking. Several consumers are sound and rendering cite:tulip_multi-threaded_2006. By modeling these systems with fusion in mind, we can eliminate some unnecessary allocations.

Another technique used to reduce allocations is by sharing the results of previous computations. This however causes a problem as the question of when a certain value will no longer be needed by the rest of the program is a difficult question to answer by simply analyzing the code. The modern solution to this problem is an automatic memory management process called garbage collection. This process freezes the program execution and scans memory for data which is no longer being used so it can be freed. Without garbage collection, functional languages as they are implemented today, would quickly run out of memory. Beyond periodically stopping the program altogether, garbage collection removes the control of memory layout from the programmer and prevents the kinds of optimizations needed for maximum performance in a game engine. In order for a functional language to be used to build an engine, garbage collection must be reduced or eliminated.

** Minimizing Garbage Collection

Haskell uses a parallel generational garbage collection which Marlow et. al note favors short lived data cite:marlow_parallel_2008. The generational garbage collector organizes memory such that younger objects are created in one location and gradually "age". When an older generation is collected so to are the generations younger than it. One added benefit of immutability is that it allows for efficient checking of garbage given that "old" data cannot reference new data. This means that when a younger generation is collected, the garbage collector can stop its swap when it reaches data in an older generation cite:marlow_parallel_2008.

Further optimizations can be made by making use of a technique called compact regions. Yang et. al demonstrated that if an immutable structure has no references to data beyond its own, then the structure can be compressed into a contiguous region in memory cite:yang_efficient_2015. This optimization is vital to long lived data like the many character models, sound files, images, and terrain data that need to survive the length of a game. With this memory loaded into a compact region, the garbage collector would only to need to check for a single reference to the region instead of having to swap the entire structure. 

More over, Yang et. al discovered that compact regions can be written directly to files or sent over the network with the internal pointers need simply be offset to match their new spot in memory  cite:yang_efficient_2015. This would be ideal for a game involving networking. Serialization is a expensive even in traditional programming languages.

** Eliminating Garbage collection

Languages like C++ and Rust have mechanisms which track the lifetime of values throughout a program and free memory when "owner" values are freed. This system is possible to emulate in functional languages through an alteration of the type system to include linear types. A linear types force all values to be used and used only once cite:wadler_linear_1990. If values are not shared between computations, then the compiler can optimize in ways it could not otherwise.

\begin{spacing}{0.5}
\begin{lstlisting}[language=Haskell, xleftmargin=.2\textwidth]

f x = (x,x) -- Error! Cannot duplicate value! 
f x y = x   -- Error! Value 'x' not used!

\end{lstlisting}
\end{spacing}
\vspace{5mm}

Bernardy et. al found that linear type systems could be added to existing, lazy languages like Haskell without modification to existing functions. This addition allows for O(1) updates to the value instead of an O(n) copy cite:bernardy_linear_2017. Linear values would reduce the amount of memory used by the program and thus reduce garbage collection. Lafont used linear types to develop a language which used a mixture of strict and lazy evaluation without garbage collection cite:lafont_linear_1988. By taking advantage of linear types within the game engine, many values can be managed outside of the normal garbage collected memory space.


* Conclusions

By making use of modern research into functional programming languages, it appears possible to achieve a parallel game engine while maintaining an expressive system for designing games. Immutability and referential transparency make any process within the engine trivially parallelizable. The traditional game loop translates into a functional reactive framework which allows various updates within the world to be modeled in a consistent way. Using software transactional memory, updates to the game state can be made without the dangers of dead locks. Using techniques like fusion, compact regions, and linear types, garbage collection can be minimized or even eliminated. While there may exist frameworks which allows for a game engine to be parallelized within traditional paradigms, the functional approach provides the most direct means to achieve parallel execution. 

** Future work

- flesh out the design of sublanguage for defining game mechanics
  - Are there primitives for typical scripts and can they be optimized?
- generate shader code in Haskell
- using strictness analysis to remove indirections in code
- adding direct support for modern artifical intelligence techniques

bibliography:refs.bib
bibliographystyle:apacite

\begin{appendices}

* Experimental Plan

This paper outlines a possible design for a game engine designed for parallel execution. In order to measure the effectiveness of the design, a prototype implementation would be needed. The prototype would be subject to several benchmarking and performance profiling techniques.

** Data to be collected

There are several dimensions of game engine performance. CPU usage is measured in units of time a process spends working on the processing unit. This measurement does not include kernel interrupts. Given the nature of a parallel engine, the CPU metric would be extended to total utilization over multiple cores. RAM usage is measured in storage units of megabytes. Frames per second is a measure of how quickly the engine can render the next frame. Each of these dimensions will be measured over a period of time. 

** Equipment needed

These test will be run on several machines with different CPUs. Several multi-core architectures will be tested, ranging from dual core to eight core chip sets from both Intel and AMD.

** Research Methods

There will be three tests:
- Simulation of 40,000 particles.
- Simulation of 1,000 animated entities with 50,000 polygons each.

Particle simulations help test the performance of an engine with a shear number of simple entities. 40,000 particles is the current industry standard for these kinds of tests. The animated entity test measures how well the engine can handle high amounts of vertex information within a scene. The high memory load will test how much the system needs to garbage collect.

The performance results of the prototype engine will be compared to the performance of similar tests run in both the Unreal and Unity engines. Each test will run its simulation for roughly a minute and will be repeated several hundred times to allow for statistical analysis. Frames per second will be outputted by the engine itself, RAM usage will be monitored using system tools on the test systems, and CPU usage will be measured using the program Threadscope.

The results will be averaged for each machine and the results will be analyzed to see how the performance changes as the number of cores increases and compared between the two chip architectures.

* Literature Review


\end{appendices}
