# org-mode settings
#+STARTUP: indent
#+STARTUP: hidestar

# paper meta 
#+TITLE: A Pure and Parallel Game Engine
#+AUTHOR: Jeffrey Dwyer
#+DATE: 11/01/2017
#+OPTIONS: toc:nil

# latex options
#+LATEX_HEADER: \usepackage[margin=1.0in]{geometry}
#+LATEX_HEADER: \usepackage{apacite}
#+LATEX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{setspace}
#+LATEX_HEADER: \linespread{2.0}
#+LATEX_CLASS_OPTIONS: [12pt]

\begin{abstract}

This paper addresses the limited capacity of modern game engines take advantage of multiple processors by applying techniques from purely functional languages to achieve a design which allows for parallelization by default. This design will then be structured using functional reactive programming and optimized using various techniques like compact regions and fusion.

\end{abstract}

* Introduction

Game engines stand in the cross roads of many fields, benifiting from research ranging from physical simulations to artifical intelligence. Popular engines like Unity break down into several modules, artifical intelligence, physics, scripting, input, multimedia, and networking cite:messaoudi_dissecting_2015. 

The high performance demanded of games forces their engines to be optimized so that all of the intensive calculations for a single frame of the game must fit within a mere sixteen milisecond window, the typical time span needed to achieve a frame rate of sixity frames per second. The common approach for the past few decades has been to optimize engines for single processor machines and such an approach has been successful due to the rate at which processing power has increased. The famous Moore's Law predicted a doubling of computing power every two years cite:present_cramming_2000. This pace was continuous until around 2015 when companies like Intel announced that their pace had slowed to almost two and a half years with a predicted geometric slowing every year. With processors reaching the physical limits of their individual capabilities, there has been a movement towards mutlicore design in software to compensate cite:theis_end_2017.

Unfortunately, years of optimization for a single core processor leaves many of the most popular game engines unable to adapt to multicore designs without massive reworkings cite:anderson_case_2008. This is unfortunate because many aspects of modern engine architectures actually lend themselves towards parallel execution. 

* Game Engine Architecture


All graphical programs follow a similar flow in their execution. First, they will collect input from user interfaces like keyboards and the mouse. This input information is then fed into an internal logic for the system which then calculates the a new system state cite:czaplicki_asynchronous_2013. The system state is finally converted into the displayed image on the computer screen and the process repeates. Game engines follow a similar pattern, except the interal logic is typically divided more explicitly. 

Tagliasacchi et. al describes the engine update as a flow of data from user input to the resulting image. The process begins with user input given to the individual entities within the virtual scene which then decide what actions they are going to take that frame. Once the entities have calculated how they will change the world and affect other entities, these changes are given to a physics simulation which then implements and movements or forces exerted within the world. Any collisions that occur, with the ground for example, are taken into account and the entities are allowed to react to this information. At this point, the state for the frame has been calculated and the positions and orientations of models within the world are passed on to a rendering process which will create a frame to be displayed cite:tagliasacchi_cascade:_2008.

Modern games have potentially thousands of complex entities within the game world, putting even more pressure on the engine to complete its tasks as soon as possible. Typical tactics to achieve speed involve special algorithms to try and minimize the actual work to do, minimizing the number of allocations made in system memory, and keeping related information closer in memory to optimize spatial locality. These techniques apply to multicore designs as well as single processor architectures. There are however, certain advantages that a multicore system would have over standard implementations today.
 
* Achieving a Parallel Design 

For two tasks to be run at the same time, their results must be independent of eachother. While data in a game engine flows through the system in a linear fashion, most of the time there are calculations which can be completed in parallel. For example, each unit of artificial intelligence within the system might be able to decide on its next action based solely on how the world was configured in the previous frame. In situations like this, each unit simply needs access to the previous state of the world and it can then be run at any time and in any order in relation to the other units. It turns out that most systems within the engine have this property. There are only two portions of the engine which are completely serial, the construction of the render tree and iteraction resolution cite:tulip_multi-threaded_2006.

The render tree is a data structure which the rendering module uses to determine the order in which to draw elements to the screen. With certain visual effects, like transparency, the order of rendering matters. For instance, transparent objects must be rendered after other objects in the scene to achieve the transparency. Other effects might be rendered over multiple passes or require the pixels from the previous pass in order to render, like motion blurs. Because this process depends heavily on a serial ordering it is impossible to parallelize, even in fully featured and popular game engines like Unity, most of the work is done in the rendering modules of the engine cite:messaoudi_dissecting_2015.

Interaction resolution consists of resolving conflicting interactions between entities. This mostly occurs after the physics simulaiton where objects collide with eachother. The discrete nature of physics simultations allows for objects to temporarily interesect and thus must be corrected before the rest of the scene state may be calculated. Similar to rendering order, the results of future resolutions depend on previous ones, so this process cannot be parallelized. Beyond these two systems most of the remaining processes can incorperate some level of parallel execution. 

** Applying Parallelism

There are several considerations to be taken when parallelizing the engine. First, the number of threads should be minimized to the number of cores available. Second, the creation and descrution of threads should be avoided while processing data. Third, the synchonization between threads should be minimzed. Finally, the workload should be balanced across threads cite:tulip_multi-threaded_2006.

Several features which can be parallelized are: interpolation of animations, the application of lighting and textures, sound source contributions, rendering frames between updates cite:tulip_multi-threaded_2006. These seperate tasks begin to outline different tasks within the engine. In his white paper, Andrews suggests divide the work of between different managers and using them to generate and distribute tasks to various worker treads. These tasks are created via messages between the different managers. When the next frame is to be calculated, each manager would determine what work that subsystem needs to do, running entity scripts for example, and generate messages to other managers when needed. In this model, the managers serve as the main division of work amongst the different CPU cores. Balance across the various cores is achieved by only dividing the managers if there are enough threads to do so cite:andrews_designing_2009.

Although this design presents a simply method of converting existing architectures into parallel ones, there remains several challenges to overcome. One of the main concerns in concurrent programming is the possibility of dead locks, a situation in which many seperate processes are waiting on eachother in a cycle for some resource. While work is seperated between managers, there is no guarentee that each subsystem will not affect the data needed by other systems. In most programming langauges, there is no real restriction on what processes can modify, infact engines often take advantage of this to increase efficiency in some cases. When translating these modules into a parallel system, any data which would be used by different processes would have to be put under a lock, allowing only one thread to work with the data at any given time. If a thread needs to modify data which is currently locked, it can only wait until the lock is lifted. If the waiting queue for locks ever becomes cyclical, then the system stops because no work can be done, a dead lock. 

One technique to avoid dead locks is software transactional memory (STM). This methodology performs small, reversable tasks which either complete successfuly or are rolled back. Atomicity, a name given to the previous features, is what allows for normal locking to be avoided all together using STM. Lock free data structures using STM are faster than their locking counterparts, however programming using STM is complex in languages that do not directly support it cite:discolo_lock_2006. These challenges are not unique to game engines and their solution may come from a more general approach to simplifying parallel design.

** Functional Programming

In his turing award lecture, John Backus posed the question of whether programming languages could grow out of their trend of becoming larger, but not more expressive. He noted that the many change parts of existing languages have little to no expressive power, thus leading to so many features being built into the langauge itself. These properities make such languages difficult to reason about. He concluded by proposing functional programming as an alternative cite:backus_can_1978. 

Functional programming is a model of computation based on the Lambda Calculus of Alonzo Church and naturally lends itself to parallel computing given the semantic differences from normal programming styles cite:backus_can_1978. Instead of building a system using a series of steps, programs can be thought of as a series of almost algebreic expressions.

\begin{spacing}{0.5}
\begin{lstlisting}[language=Haskell, caption=Example of lambda evaluation]

(\lambda x. \lambda y. add x y) 5 6
(\lambda y. add 5 y) 6
(add 5 6)
11 

\end{lstlisting}
\end{spacing}


Semantically, lambda calculus evaluates programs by replacing input symbols with their input. In traditional languages this is achieved by "passing" values as parameters into functions. Unlike traditional languages, the entire structure of a functional program is built with lambda expressions. The runtime of such a language differs drastically from langauges like C, with the order of evaluation taken out of the hands of the programmer cite:jones_implementing_1993. In modern langauges like Haskell, this leads to far simpler programs. For example, the classic quicksort algorithm's semantics are obscured in languages like C.

\begin{spacing}{0.5}
\begin{lstlisting}[language=C, caption=Quicksort in C]
void quicksort(int *A, int len) {
  if (len < 2) return;
 
  int pivot = A[len / 2];
 
  int i, j;
  for (i = 0, j = len - 1; ; i++, j--) {
    while (A[i] < pivot) i++;
    while (A[j] > pivot) j--;
 
    if (i >= j) break;
 
    int temp = A[i];
    A[i]     = A[j];
    A[j]     = temp;
  }

  quicksort(A, i);
  quicksort(A + i, len - i);
}
\end{lstlisting}
\end{spacing} 
\vspace{5mm}

However, in languages like Haskell, the semantics of the algorithm can be expressed directly in an almost mathematical definition. The left side of the equation is the name of the function and it's inputs with the resulting expression on the right, much like a funciton in algebra. This maps to the parenthized form of lambdas shown before.

\begin{spacing}{0.5}
\begin{lstlisting}[language=Haskell, caption=Quicksort in Haskell] 
qsort :: Ord a => [a] -> [a]
qsort [] = []
qsort (x:xs) = qsort ys ++ x : qsort zs
  where
    (ys, zs) = partition (< x) xs 

\end{lstlisting}
\end{spacing}
\vspace{5mm}

The differences are not only visual, the semantics of the language itself are simpler. One of the main challenges with programming is keeping track of how the state application changes throughout execution. These changes could be updates to values like a name or whether a button is turned on or off. Typical languages like C allow the user to change program state anywhere at anytime, which causes problems when trying to run tasks in parallel. 

#+CAPTION: The Quicksort function as a graph
[[./function-graph-example.png]]

Functional languages can represent each computation as a graph. Because there is no dependencies on state between any of the leaves in such graphs, each can be evaluated and reduced in any order or at the same time. It is this property which makes langauges like Haskell so easy to run in parallel. Most programs need only a small annotation to indicate that the expression should be evaluated at the same time as the others.

\begin{spacing}{0.5}
\begin{lstlisting}[language=Haskell, caption=Parallel Quicksort in Haskell] 
qsort :: Ord a => [a] -> [a]
qsort [] = []
qsort (x:xs) = (qsort ys `using` reseq) ++ x : (qsort zs `using` rseq)
  where
    ys = filter (< x) xs `using` rseq
    zs = filter (>= x) xs `using` rseq

\end{lstlisting}
\end{spacing}
\vspace{5mm}

While this solves one problem, it caues another because creating new values for every calculation comes at a cost which is unacceptable in programs like game engines where every ounce of speed is needed. Another issue is that functional languages, Haskell included, manage their memeory using automatic processes called garbage collection. Every so often, the program will be paused so memory which is no longer needed can be freeded. Again, these types of delays prevent the kind of performance needed by modern video games. 

The rest of this paper will address redesigning the structure of a typical game engine to fit a functional style and then cover various techniques for reducing or eliminating the performance concerns of this style.
 
* Representing the game loop using functional reactive programming 

Game engines are similar to most other graphical programs that users would interact with cite:tulip_multi-threaded_2006. Graphical application frameworks today take user input and allow for individual components of the application handle the inputs. An example would be a button which, when clicked, modifies the state of a pop up to be activated. This localized view of the system has several draw backs, but most important to the design of the engine, it obscures which entities have interactions with other entities. 

In a functional paradigm where arbitrary modifications of data are not allowed, the relations between different entities must be made explicit. As such, there is a movement towards so called "Reactive" systems which model the application like a circuit which information flows through to produce an output, the new displayed user interface. The functional approach to these semantics is aptly called, "Functional Reactive Programming" or FRP. In his formulation of FRP, Elliot defined the system based on two primative types, Bheaviours, Events, and a set of combinators for generating new values based on those primatives cite:elliott_push-pull_2009. 

Elliot describes behaviors as functions from time to a value. An example of this would be a ball in the air whose height is dependent on time and the velocity of the ball. As time progresses, the hieght of the ball decreases. These behaviors can be used to create more behaviours which depend on other streams of values. And example of a more complex behavior would be an object in the virtual world which was dependent on the location of the player's mouse at any given time. Character animations also fall under the category of a behavior. As time progresses, the animation progresses one frame, changing the configuration of the model skeleton causing movement.

An Event is a function from time to a possible value. The classic example of an event would be a mouse click. If one where to plot the function of an event it would remain mostly at zero until the event occured, which would be visiable as a small spike in the value before it returns to nothing. Events can be used to model discrete occurences within the system which are then used by behaviors to alter the interface cite:wan_functional_2000.

#+CAPTION: A reactive network for unit position
[[./frp-unit-example.png]]

** Alnterative and Improved formulations of FRP

In the above example, we can see two behaviors, the player unit's position and the alarm's position. Over time, the player's position will change which causes the active state of the alarm to be recalculated. Here, the difference between the player's position and the alarm is calcuated and then that result is checked to see if it is less than five. The alarm triggering can be considered an event since it only occurs at discrete points in time.
 
Although FRP creates a rich and expressive style to model a game engine with, there are several performance issues with the semantics as originally defined. For instance, given that all values are dependent on time, all values within the system must be constantly recalculated, which causes large amounts of wastful work calculating values which have not changed. Another problem is that the original semantics also force all previous values for behaviors and events to be stored for the duration of the program. As time progresses, the memory usage slowly builds. This is unacceptable for a game engine, but there are other formulations of FRP which drastically reduce the problems with Elliot's initial design.

In Czaplicki and Chong's formulation of FRP, changes do not propogate unless a discrete event occurs. This change, while unfaithful to the original semantics of FRP, is much more suited for graphical interfaces due to that face that the user can only interact with the system in discrete ways cite:czaplicki_asynchronous_2013. While certain systems would change continuously with time, like the physics simulation, the vast majority of components will only ever change with discrete events. This reduces the amount of recalculations needed.

In his reformulation of the original FRP semantics, Elliott introduced the idea of reactive values and push-pull semantics to address the same performance issues. Reactive values allow for changes to certain values to be propogated or pushed through the system, leaving pull based updates to time dependent events. These reactive values allow for the same mental model for behaviors to be used without the performance loss cite:elliott_push-pull_2009.

In Nilsson et. all's continuation formulation of FRP, behaviors can be modeled as transition functions which return how they will behave after a discrete time change. By removing behaviors as first class within the framework, the previous performance costs are reduced and the semantics of working with behaviors is simplified cite:nilsson_functional_2002.

The game loop for a parallel engine can thus be described as a flow which takes user input, time, and the state of the world in the previous frame and then uses each as events and behaviors for calculating the next frame. A stream of messages can be used to model the communication of certain entities with eachother. These messages can be interpreted at a synchronization point before rendering which interprets the messages and uses STM to safely modfiy data or otherwise pass the message on to the next frame to be handled by the appropriate entities.

In this design, all entities can calculate their changes to themselves and the world in paralell and thus the workload can be balanced across the processors at a fine grained level. This is an improvement over the manager approach to parallelization in that managers were forced onto a single processor and unable to share their workloads with other managers which might have finished their tasks sooner.
  
* Addressing Efficency Concerns 

Although pure functional programming allows for expressivity and simple parallelization, there are performance costs which must be addressed. 

Pure code also causes new allocations for every change or update to existing data. Operations on existing data are cheap time-wise, but creating new data is expensive. Many optimizations done by modern engines focus on reusing existing data to prevent new allocations whenever possible. Luckily, pure functional languages allow for the compiler to perform many complex optimizations not possible in other languages. Once technique for reducing allocations is to elimating intermediate data from being created between data producers and data consumers, also known as fusion. 

** Fusion

Fusion eliminates intermidate data strctures like a lists due to the properties of the functions. In the functional style, functions like map, fold, and filter are common tools used to manipulate data structures. Due to referential transparency, functions can be manipulated almost like algebreic expression in math where redundancies can be removed. 

\begin{spacing}{0.5}
\begin{lstlisting}[language=Haskell]

map (g . f) = map g . map f

\end{lstlisting}
\end{spacing}
\vspace{5mm}

In the case of the function map, which applies a function to all values of a list, the composition of two maps is equal to mapping the composition of both functions. So rather than create a new list for the result of map f and then a new structure for map g, the optimized version simply applies (g . f) to every element of the input list and creates only a single new list. List are not the only structures which can benifit from fusion. 

Meijer et. al formalized several recursion schemes which could replace normal recursion as the basic building block of functional programs. These recursion schemes were divided into two categories, anamorphisms, which produce new values and catamorphisms, which consume values. In general, it is the pairing of an anamorpic producer and a catamorphic consumer that allows for fusion to occur cite:meijer_functional_1991. Fusion can occur for any recursive data structures, not just lists cite:bernardy_composable_2016.

Certain modules within the engine serve only to produce or consume data. Several producers are user input and networking. Several consumers are sound and rendering cite:tulip_multi-threaded_2006. By modeling these systems with fusion in mind, we can eliminate some unecessary allocations.

Another technique used to reduce allocations is by sharing the results of previous computations. This however causes a problem as the question of when a certain value will no longer be needed by the rest of the program is a difficult question to answer by simply analyzing the code. The modern solution to this problem is an automatic memory managment process called garbage collection. This process freezes the program execution and scans memory for data which is no longer being used so it can be freed. Without garbage collection, functional languages as they are implemented today, would quickly run out of memory. Beyond periodically stopping the program altogether, garbage collection removes the control of memory layout from the programmer and prevents the kinds of optimizations needed for maximum performance in a game engine. In order for a functional language to be used to build an engine, garbage collection must be reduced or eliminated.

** Minimizing Garbage Collection

Haskell uses a parallel generational garbage collection which Marlow et. al note favors short lived data cite:marlow_parallel_2008. The generational garbage collector organizes memory such that younger objects are created in one location and gradually "age". When an older generation is collected so to are the generations younger than it. One added benifit of immutability is that it allows for efficent checking of garbage given that "old" data cannot reference new data. This means that when a younger generation is collected, the garbage collector can stop its sweap when it reaches data in an older generation cite:marlow_parallel_2008.

Further optimzations can be made by making use of a technique called compact regions. Yang et. al desmonstrated that if an immutable structure has no references to data beyond its own, then the structure can be compressed into a contiguous region in memory cite:yang_efficient_2015. This optimization is vital to long lived data like the many character models, sound files, images, and terrain data that need to survive the length of a game. With this memeory loaded into a compact region, the garbage collector would only to need to check for a single reference to the region instead of having to sweap the entire structure. 

More over, Yang et. al discovered that compact regions can be written directly to files or sent over the network with the internal pointers need simply be offset to match their new spot in memory  cite:yang_efficient_2015. This would be ideal for a game involving networking. Serialization is a expensive even in traditional programming languages.

** Eliminating Garbage collection

A linear type system is one which forces all values to be used and used only once cite:wadler_linear_1990.

\begin{spacing}{0.5}
\begin{lstlisting}[language=Haskell]

f x = (x,x) -- Error! Cannot duplicate value! 
f x y = x   -- Error! Value 'x' not used!

\end{lstlisting}
\end{spacing}

Bernardy et. al found that linear type systems could be added to existing, lazy languages like Haskell without modification to existing functions. This addition allows for O(1) updates to the value instead of an O(n) copy cite:bernardy_linear_2017. Linear values would reduce the amount of memory used by the program and thus reduce garbage collection.

Lafont used linear types to develop a language which used a mixture of strict and lazy evaluation without garbage collection cite:lafont_linear_1988.


* Conclusions

By making use of modern research into functional programming languages, it appears possible to achieve a parallel game engine while maintaining an expressive system for designing games. Immutability and referential transparency make any process within the engine trivally parallelizable. The traditional game loop translates into a functional reactive framework which allows various updates within the world to be modeled in a consistent way. Using software transactional memory, updates to the game state can be made without the dangers of dead locks. Using techniques like fusion and compact regions, garbage collection can be minimized. 


bibliography:refs.bib
bibliographystyle:apacite
