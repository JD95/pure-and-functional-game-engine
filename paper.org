# org-mode settings
#+STARTUP: indent
#+STARTUP: hidestar

# paper meta 
#+TITLE: A Pure and Functional Game Engine
#+AUTHOR: Jeffrey Dwyer
#+DATE: 09/27/2017
#+OPTIONS: toc:nil

# latex options
#+LATEX_HEADER: \usepackage[margin=1.0in]{geometry}
#+LATEX_HEADER: \linespread{2.0}
#+LATEX_CLASS_OPTIONS: [12pt]

* Abstract


* Introduction

Game engines stand in the cross roads of many fields, benifiting from research ranging from physical simulations to artifical intelligence. Popular engines like Unity break down into several modules, artifical intelligence, physics, scripting, input, multimedia, and networking cite:messaoudi_dissecting_2015. 

The high performance demanded of games forces their engines to be optimized so that all of the intensive calculations for a single frame of the game must fit within a mere sixteen milisecond window, the typical time span needed to achieve a frame rate of sixity frames per second. The common approach for the past few decades has been to optimize engines for single processor machines and such an approach has been successful due to the rate at which processing power has increased. The famous Moore's Law predicted a doubling of computing power every two years. This pace was continuous until around 2015 when Intel announced that its pace had slowed to almost two and a half years with a predicted geometric slowing every year. With processors reaching the physical limits of their individual capabilities, there has been a movement towards mutlicore design in software to compensate.

Unfortunately, years of optimization for a single core processor leaves many of the most popular game engines unable to adapt to multicore designs without massive reworkings. This is unfortunate because many aspects of modern engine architectures actually lend themselves towards parallel execution. 

* Game Engine Architecture


All graphical programs follow a similar flow in their execution. First, they will collect input from user interfaces like keyboards and the mouse. This input information is then fed into an internal logic for the system which then calculates the a new system state. The system state is finally converted into the displayed image on the computer screen and the process repeates. Game engines follow a similar pattern, except the interal logic is typically divided more explicitly. User input is normally given to the individual entities within the virtual scene which then decided what actions they are going to take that frame. Once the entities have calculated how they will change the world and affect other entities, these changes are given to a physics simulation which then implements and movements or forces exerted within the world. Any collisions that occur, with the ground for example, are taken into account and the entities are allowed to react to this information. At this point, the state for the frame has been calculated and the positions and orientations of models within the world are passed on to a rendering process which will create a frame to be displayed.

Modern games have potentially thousands of complex entities within the game world, putting even more pressure on the engine to complete its tasks as soon as possible. Typical tactics to achieve speed involve special algorithms to try and minimize the actual work to do, minimizing the number of allocations made in system memory, and keeping related information closer in memory to optimize spatial locality. These techniques apply to multicore designs as well as single processor architectures. There are however, certain advantages that a multicore system would have over standard implementations today.
 
- Several features which can be parallelized are: interpolation of animations, the application of lighting and textures, sound source contributions, rendering frames between updates cite:tulip_multi-threaded_2006.
- Certain modules within the engine serve only to produce or consume data. Several producers are user input and networking. Several consumers are sound and rendering cite:tulip_multi-threaded_2006.
- Even in fully featured and popular game engines like Unity, most of the work is done in the rendering modules of the engine cite:messaoudi_dissecting_2015.
  
* Achieving a Parallel Design 

For two tasks to be run at the same time, their results must be independent of eachother. While data in a game engine flows through the system in a linear fashion, most of the time there are calculations which can be completed in parallel. For example, each unit of artificial intelligence within the system might be able to decide on its next action based solely on how the world was configured in the previous frame. In situations like this, each unit simply needs access to the previous state of the world and it can then be run at any time and in any order in relation to the other units. It turns out that most systems within the engine have this property. There are only two portions of the engine which are completely serial, the construction of the render tree and iteraction resolution cite:tulip_multi-threaded_2006.

The render tree is a data structure which the rendering module uses to determine the order in which to draw elements to the screen. With certain visual effects, like transparency, the order of rendering matters. For instance, transparent objects must be rendered after other objects in the scene to achieve the transparency. Other effects might be rendered over multiple passes or require the pixels from the previous pass in order to render, like motion blurs. Because this process depends heavily on a serial ordering it is impossible to parallelize.

Interaction resolution consists of resolving conflicting interactions between entities. This mostly occurs after the physics simulaiton where objects collide with eachother. The discrete nature of physics simultations allows for objects to temporarily interesect and thus must be corrected before the rest of the scene state may be calculated. Similar to rendering order, the results of future resolutions depend on previous ones, so this process cannot be parallelized. Beyond these two systems most of the remaining processes can incorperate some level of parallel execution. 

There are several considerations to be taken when parallelizing the engine. First, the number of threads should be minimized to the number of cores available. Second, the creation and descrution of threads should be avoided while processing data. Third, the synchonization between threads should be minimzed. Finally, the workload should be balanced across threads cite:tulip_multi-threaded_2006.

In his white paper, Andrews suggests divide the work of the engine between different managers and using them to generate and distribute tasks to various worker treads. These tasks are created via messages between the different managers. When the next frame is to be calculated, each manager would determine what work that subsystem needs to do, running entity scripts for example, and generate messages to other managers when needed. In this model, the managers serve as the main division of work amongst the different CPU cores. Balance across the various cores is achieved by only dividing the managers if there are enough threads to do so cite:andrews_designing_2009.

Although this design presents a simply method of converting existing architectures into parallel ones, there remains several challenges to overcome. One of the main concerns in concurrent programming is the possibility of dead locks, a situation in which many seperate processes are waiting on eachother in a cycle for some resource. While work is seperated between managers, there is no guarentee that each subsystem will not affect the data needed by other systems. In most programming langauges, there is no real restriction on what processes can modify, infact engines often take advantage of this to increase efficiency in some cases. When translating these modules into a parallel system, any data which would be used by different processes would have to be put under a lock, allowing only one thread to work with the data at any given time. If a thread needs to modify data which is currently locked, it can only wait until the lock is lifted. If the waiting queue for locks ever becomes cyclical, then the system stops because no work can be done, a dead lock. 

One technique to avoid dead locks is software transactional memory (STM). This methodology performs small, reversable tasks which either complete successfuly or are rolled back. Atomicity, a name given to the previous features, is what allows for normal locking to be avoided all together using STM. Lock free data structures using STM are faster than their locking counterparts, however programming using STM is complex in languages that do not directly support it cite:discolo_lock_2006. These challenges are not unique to game engines and their solution may come from a more general approach to making parallel design easy.

With the growing interest in parallel computing, the functional programming paradigm has made a resurgence. Functional programming differentiates itself from the currently popular imperative paradigm by not structuring programs as a series of steps for the computer to take, but rather as descriptions simple mappings from input values to output values which are composed to make larger programs. So rather than directly manipulating data which the user creates and destroys, the programmer instead assumes that data cannot be changed and creates new data with changed values. While this approach seems clumbersome at first, this style allows for clearer and more easily optimized code.

More importantly, if the default semantics of the program is immutability, then even if the program was run in parallel, data shared between threads would never be modified by default. This allows the programmer to have a much finer grained control over when locking is needed. Moreover, given that all functions only depend on their input to computer their output, so long as the input is available for a function it can be run in parallel with anything else. Parallelism in this paradigm becomes almost trivial and is thus an ideal framework with which to structure the rest of the engine. To make the design more concrete, the rest of the paper will use the language Haskell to describe the different components of the engine as it forces a pure functional style. 

There are two challenges going forward with a purely functional design that will be addressed by the next two sections. First, the drastic change in programming semantics between normal languages and Haskell requires that conventional designs for a game engine be reworked to accomodate immutability and take advantage of properties like strong types and first class functions. Second, languages like Haskell do not allow the same kind of control over memory as languages like C do, and the ineffiencies caused by artifacts like garbage control and data indirection must be addressed to achieve the performance necessary for standard game engines.

* Feasability of design in large scale applications.

- Functional reactive programming is a formal formal semantics of a reactive system based on two primative types, Bheaviours, Events, and a set of combinators for generating new values based on those primatives. A Behavior is a function from time to a value. An Event is a function from time to a possible value cite:wan_functional_2000.
- Arrowized FRP can change how signals are processed without space leaks  cite:czaplicki_asynchronous_2013.
- In their formulation of FRP, changes do not propogate unless a discrete event occurs cite:czaplicki_asynchronous_2013. This change, while unfaithful to the original semantics of FRP is much more suited for graphical interfaces due to that face that the user can only interact with the system in discrete ways. It goes without saying that the interaction model between the user and a game engine are the same as that of a normal graphical application, however this formulation can also extend to all types of events within the reactive system.
- In his reformulation of the original FRP semantics, Elliott introduced the idea of reactive values and push-pull semantics to address the same performance issues. Reactive values allow for changes to certain values to be propogated or pushed through the system, leaving pull based updates to time dependent events. This change removes much of the wasteful updates caused in the original formulation cite:elliott_push-pull_2009.
- In a continuation formulation of FRP, behaviors can be modeled as transition functions which return how they will be have with each time delta. This is implemented as a function which transforms signals. The singals themselves are not first class, thus avoiding the performance loss. cite:nilsson_functional_2002.
  
* Making it Efficent
** Analyzing Time Complexity of Functional Data Structures
*** Differences from normal data structures
*** lazieness
*** purity
*** methods
*** several useful datastructures for the game
** Garbage Collection in Haskell
- Immutability allows for efficent checking of garbage in large structures cite:marlow_parallel_2008.
- Generational garbage collection favors young objects cite:marlow_parallel_2008. 
*** Reiterate problems with GC
*** How to optimize for low GC in Haskell
** Fusion
- Using recursion schemes as the basic building block of code allows for high fusability as they use a consumer producer mode. Anamorphisms are recursive producers and catamorphisms are recursive consumers cite:meijer_functional_1991.
- Fusion allows for various intermediate data structures to be eliminated during compilation cite:bernardy_composable_2016.
*** Consumer - Producer pattern
*** Recursion Schemes
*** Application to engine
** Compact Regions
- Immutable data with no outgoing pointers is best suited for networking and serialization  cite:yang_efficient_2015.
- Compact regions can be written directly to files or sent over the network. The internal pointers need simply be offset to match their new spot in memory  cite:yang_efficient_2015.
- The property of no outgoing pointers means that only the top level reference to the structure need be checked during garbage collection  cite:yang_efficient_2015.
*** What are compact regions
*** How they're used
*** Application to engine
** Linear Types
*** Linear Logic
*** Implications on GC
*** Application to engine

* Conclusions

By making use of modern research into functional programming languages, it appears possible to achieve a parallel game engine while maintaining an expressive system for designing games.

bibliography:refs.bib
bibliographystyle:unsrt
