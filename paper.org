# org-mode settings
#+STARTUP: indent
#+STARTUP: hidestar

# paper meta 
#+TITLE: A Pure and Parallel Game Engine
#+AUTHOR: Jeffrey Dwyer
#+DATE: 11/01/2017
#+OPTIONS: toc:nil

# latex options
#+LATEX_HEADER: \usepackage[margin=1.0in]{geometry}
#+LATEX_HEADER: \linespread{2.0}
#+LATEX_CLASS_OPTIONS: [12pt]

* Abstract

This paper addresses the limited capacity of modern game engines take advantage of multiple processors by applying techniques from purely functional languages to achieve a design which allows for parallelization by default. This design will then be structured using functional reactive programming and optimized using various techniques like compact regions and fusion.

* Introduction

Game engines stand in the cross roads of many fields, benifiting from research ranging from physical simulations to artifical intelligence. Popular engines like Unity break down into several modules, artifical intelligence, physics, scripting, input, multimedia, and networking cite:messaoudi_dissecting_2015. 

The high performance demanded of games forces their engines to be optimized so that all of the intensive calculations for a single frame of the game must fit within a mere sixteen milisecond window, the typical time span needed to achieve a frame rate of sixity frames per second. The common approach for the past few decades has been to optimize engines for single processor machines and such an approach has been successful due to the rate at which processing power has increased. The famous Moore's Law predicted a doubling of computing power every two years. This pace was continuous until around 2015 when Intel announced that its pace had slowed to almost two and a half years with a predicted geometric slowing every year. With processors reaching the physical limits of their individual capabilities, there has been a movement towards mutlicore design in software to compensate.

Unfortunately, years of optimization for a single core processor leaves many of the most popular game engines unable to adapt to multicore designs without massive reworkings. This is unfortunate because many aspects of modern engine architectures actually lend themselves towards parallel execution. 

* Game Engine Architecture


All graphical programs follow a similar flow in their execution. First, they will collect input from user interfaces like keyboards and the mouse. This input information is then fed into an internal logic for the system which then calculates the a new system state. The system state is finally converted into the displayed image on the computer screen and the process repeates. Game engines follow a similar pattern, except the interal logic is typically divided more explicitly. User input is normally given to the individual entities within the virtual scene which then decided what actions they are going to take that frame. Once the entities have calculated how they will change the world and affect other entities, these changes are given to a physics simulation which then implements and movements or forces exerted within the world. Any collisions that occur, with the ground for example, are taken into account and the entities are allowed to react to this information. At this point, the state for the frame has been calculated and the positions and orientations of models within the world are passed on to a rendering process which will create a frame to be displayed.

Modern games have potentially thousands of complex entities within the game world, putting even more pressure on the engine to complete its tasks as soon as possible. Typical tactics to achieve speed involve special algorithms to try and minimize the actual work to do, minimizing the number of allocations made in system memory, and keeping related information closer in memory to optimize spatial locality. These techniques apply to multicore designs as well as single processor architectures. There are however, certain advantages that a multicore system would have over standard implementations today.
 
  
* Achieving a Parallel Design 

For two tasks to be run at the same time, their results must be independent of eachother. While data in a game engine flows through the system in a linear fashion, most of the time there are calculations which can be completed in parallel. For example, each unit of artificial intelligence within the system might be able to decide on its next action based solely on how the world was configured in the previous frame. In situations like this, each unit simply needs access to the previous state of the world and it can then be run at any time and in any order in relation to the other units. It turns out that most systems within the engine have this property. There are only two portions of the engine which are completely serial, the construction of the render tree and iteraction resolution cite:tulip_multi-threaded_2006.

The render tree is a data structure which the rendering module uses to determine the order in which to draw elements to the screen. With certain visual effects, like transparency, the order of rendering matters. For instance, transparent objects must be rendered after other objects in the scene to achieve the transparency. Other effects might be rendered over multiple passes or require the pixels from the previous pass in order to render, like motion blurs. Because this process depends heavily on a serial ordering it is impossible to parallelize, even in fully featured and popular game engines like Unity, most of the work is done in the rendering modules of the engine cite:messaoudi_dissecting_2015.

Interaction resolution consists of resolving conflicting interactions between entities. This mostly occurs after the physics simulaiton where objects collide with eachother. The discrete nature of physics simultations allows for objects to temporarily interesect and thus must be corrected before the rest of the scene state may be calculated. Similar to rendering order, the results of future resolutions depend on previous ones, so this process cannot be parallelized. Beyond these two systems most of the remaining processes can incorperate some level of parallel execution. 

There are several considerations to be taken when parallelizing the engine. First, the number of threads should be minimized to the number of cores available. Second, the creation and descrution of threads should be avoided while processing data. Third, the synchonization between threads should be minimzed. Finally, the workload should be balanced across threads cite:tulip_multi-threaded_2006.

Several features which can be parallelized are: interpolation of animations, the application of lighting and textures, sound source contributions, rendering frames between updates cite:tulip_multi-threaded_2006. These seperate tasks begin to outline different tasks within the engine. In his white paper, Andrews suggests divide the work of between different managers and using them to generate and distribute tasks to various worker treads. These tasks are created via messages between the different managers. When the next frame is to be calculated, each manager would determine what work that subsystem needs to do, running entity scripts for example, and generate messages to other managers when needed. In this model, the managers serve as the main division of work amongst the different CPU cores. Balance across the various cores is achieved by only dividing the managers if there are enough threads to do so cite:andrews_designing_2009.

Although this design presents a simply method of converting existing architectures into parallel ones, there remains several challenges to overcome. One of the main concerns in concurrent programming is the possibility of dead locks, a situation in which many seperate processes are waiting on eachother in a cycle for some resource. While work is seperated between managers, there is no guarentee that each subsystem will not affect the data needed by other systems. In most programming langauges, there is no real restriction on what processes can modify, infact engines often take advantage of this to increase efficiency in some cases. When translating these modules into a parallel system, any data which would be used by different processes would have to be put under a lock, allowing only one thread to work with the data at any given time. If a thread needs to modify data which is currently locked, it can only wait until the lock is lifted. If the waiting queue for locks ever becomes cyclical, then the system stops because no work can be done, a dead lock. 

One technique to avoid dead locks is software transactional memory (STM). This methodology performs small, reversable tasks which either complete successfuly or are rolled back. Atomicity, a name given to the previous features, is what allows for normal locking to be avoided all together using STM. Lock free data structures using STM are faster than their locking counterparts, however programming using STM is complex in languages that do not directly support it cite:discolo_lock_2006. These challenges are not unique to game engines and their solution may come from a more general approach to making parallel design easy.

With the growing interest in parallel computing, the functional programming paradigm has made a resurgence. Functional programming differentiates itself from the currently popular imperative paradigm by not structuring programs as a series of steps for the computer to take, but rather as descriptions simple mappings from input values to output values which are composed to make larger programs. So rather than directly manipulating data which the user creates and destroys, the programmer instead assumes that data cannot be changed and creates new data with changed values. While this approach seems clumbersome at first, this style allows for clearer and more easily optimized code.

More importantly, if the default semantics of the program is immutability, then even if the program was run in parallel, data shared between threads would never be modified by default. This allows the programmer to have a much finer grained control over when locking is needed. Moreover, given that all functions only depend on their input to computer their output, so long as the input is available for a function it can be run in parallel with anything else. Parallelism in this paradigm becomes almost trivial and is thus an ideal framework with which to structure the rest of the engine. To make the design more concrete, the rest of the paper will use the language Haskell to describe the different components of the engine as it forces a pure functional style. 

There are two challenges going forward with a purely functional design that will be addressed by the next two sections. First, the drastic change in programming semantics between normal languages and Haskell requires that conventional designs for a game engine be reworked to accomodate immutability and take advantage of properties like strong types and first class functions. Second, languages like Haskell do not allow the same kind of control over memory as languages like C do, and the ineffiencies caused by artifacts like garbage control and data indirection must be addressed to achieve the performance necessary for standard game engines.

* Feasability of design in large scale applications.

Game engines are similar to most other graphical programs that users would interact with. Graphical application frameworks today take user input and allow for individual components of the application handle the inputs. An example would be a button which, when clicked, modifies the state of a pop up to be activated. This localized view of the system has several draw backs, but most important to the design of the engine, it obscures which entities have interactions with other entities. 

In a functional paradigm where arbitrary modifications of data are not allowed, the reltations between different entities must be made explicit. As such, there is a movement towards so called "Reactive" systems which model the application like a circuit which information flows through to produce an output, the new displayed user interface. The functional approach to these semantics is aptly called, "Functional Reactive Programming" or FRP. In his formulation of FRP, Elliot defined the system based on two primative types, Bheaviours, Events, and a set of combinators for generating new values based on those primatives. 

Elliot describes behaviors as functions from time to a value. An example of this would be a ball in the air whose height is dependent on time and the velocity of the ball. As time progresses, the hieght of the ball decreases. These behaviors can be used to create more behaviours which depend on other streams of values. And example of a more complex behavior would be an object in the virtual world which was dependent on the location of the player's mouse at any given time. Character animations also fall under the category of a behavior. As time progresses, the animation progresses one frame, changing the configuration of the model skeleton causing movement.

An Event is a function from time to a possible value. The classic example of an event would be a mouse click. If one where to plot the function of an event it would remain mostly at zero until the event occured, which would be visiable as a small spike in the value before it returns to nothing. Events can be used to model discrete occurences within the system which are then used by behaviors to alter the interface cite:wan_functional_2000.

Although FRP creates a rich and expressive style to model a game engine with, there are several performance issues with the semantics as originally defined. For instance, given that all values are dependent on time, all values within the system must be constantly recalculated, which causes large amounts of wastful work calculating values which have not changed. Another problem is that the original semantics also force all previous values for behaviors and events to be stored for the duration of the program. As time progresses, the memory usage slowly builds. This is unacceptable for a game engine, but there are other formulations of FRP which drastically reduce the problems with Elliot's initial design.

In Czaplicki and Chong's formulation of FRP, changes do not propogate unless a discrete event occurs. This change, while unfaithful to the original semantics of FRP, is much more suited for graphical interfaces due to that face that the user can only interact with the system in discrete ways cite:czaplicki_asynchronous_2013. While certain systems would change continuously with time, like the physics simulation, the vast majority of components will only ever change with discrete events. This reduces the amount of recalculations needed.

In his reformulation of the original FRP semantics, Elliott introduced the idea of reactive values and push-pull semantics to address the same performance issues. Reactive values allow for changes to certain values to be propogated or pushed through the system, leaving pull based updates to time dependent events. These reactive values allow for the same mental model for behaviors to be used without the performance loss cite:elliott_push-pull_2009.

In Nilsson et. all's continuation formulation of FRP, behaviors can be modeled as transition functions which return how they will behave after a discrete time change. By removing behaviors as first class within the framework, the previous performance costs are reduced and the semantics of working with behaviors is simplified cite:nilsson_functional_2002.

The game loop for a parallel engine can thus be described as a flow which takes user input, time, and the state of the world in the previous frame and then uses each as events and behaviors for calculating the next frame. A stream of messages can be used to model the communication of certain entities with eachother. These messages can be interpreted at a synchronization point before rendering which interprets the messages and uses STM to safely modfiy data or otherwise pass the message on to the next frame to be handled by the appropriate entities.

In this design, all entities can calculate their changes to themselves and the world in paralell and thus the workload can be balanced across the processors at a fine grained level. This is an improvement over the manager approach to parallelization in that managers were forced onto a single processor and unable to share their workloads with other managers which might have finished their tasks sooner.
  
* Addressing Efficency Concerns 

Although pure functional programming allows for expressivity and simple parallelization, there are performance costs which must be addressed. Pure code causes new allocations for every change or update to existing data. As an optimization to prevent such wasteful reallocation, most data structures are designed to share unchanged values between versions. For instnace, if a complex entity with many parts merely has a change to its health, only the value for the health needs to allocate a new value isntead of the entire unit. This style is only possible with a tree like structure in memory which causes problems for optimizing spatial locality. Reducing allocations is thus a main concern with a functional engine. The purity of a language allows for powerful optimizations done by the compiler, one of which is fusion.

Fusion is the elimination of an intermidate data strcture like a list due to the properties of the functions. In the functional style, functions like map, fold, and filter are common tools used to manipulate data structures. Due to referential transparency, functions can be manipulated almost like algebreic expression in math where redundancies can be removed. In terms of fusion, there is a general pattern which allows for the intermediate structure to be eliminated.

Meijer et. al formalized several recursion schemes which could replace normal recursion as the basic building block of functional programs. These recursion schemes were divided into two categories, anamorphisms, which produce new values and catamorphisms, which consume values. In general, it is the pairing of an anamorpic producer and a catamorphic consumer that allows for fusion to occur cite:meijer_functional_1991. Fusion can occur for any data structures, not just lists cite:bernardy_composable_2016.

Certain modules within the engine serve only to produce or consume data. Several producers are user input and networking. Several consumers are sound and rendering cite:tulip_multi-threaded_2006. By modeling these systems with fusion in mind, we can eliminate unecessary allocations.

Also unlike normal styles, functional programming languages rely on automatic garbage collection which freezes the program while unused memory is freed. While these times are relativtely short in most programs, the delay within the window of sixten miliseconds for game engines causes unacceptable framerate drops. Foretunately there are tactics with which to minimize or eliminate the need for garbage collection. 

Haskell uses a parallel generational garbage collection which Marlow et. al note favors short lived data cite:marlow_parallel_2008. The generational garbage collector organizes memory such that younger objects are created in one location and gradually "age". When an older generation is collected so to are the generations younger than it. One added benifit of immutability is that it allows for efficent checking of garbage given that "old" data cannot reference new data. This means that when a younger generation is collected, the garbage collector can stop its sweap when it reaches data in an older generation cite:marlow_parallel_2008.

Further optimzations can be made by making use of a technique called compact regions. Yang et. al desmonstrated that if an immutable structure has no references to data beyond its own, then the structure can be compressed into a contiguous region in memory cite:yang_efficient_2015. This optimization is vital to long lived data like the many character models, sound files, images, and terrain data that need to survive the length of a game. With this memeory loaded into a compact region, the garbage collector would only to need to check for a single reference to the region instead of having to sweap the entire structure. 

More over, Yang et. al discovered that compact regions can be written directly to files or sent over the network with the internal pointers need simply be offset to match their new spot in memory  cite:yang_efficient_2015. This would be ideal for a game involving networking. Serialization is a expensive even in traditional programming languages.

* Conclusions

By making use of modern research into functional programming languages, it appears possible to achieve a parallel game engine while maintaining an expressive system for designing games. Immutability and referential transparency make any process within the engine trivally parallelizable. The traditional game loop translates into a functional reactive framework which allows various updates within the world to be modeled in a consistent way. Using software transactional memory, updates to the game state can be made without the dangers of dead locks. Using techniques like fusion and compact regions, garbage collection can be minimized. 

bibliography:refs.bib
bibliographystyle:unsrt
